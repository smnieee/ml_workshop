{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_TrainTestValidate.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "j9G0Eqrng7G3"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twcde8yCo2wN"
      },
      "source": [
        "# Train, Test, Validate Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-jl-L0Q_bEA"
      },
      "source": [
        "## Setup\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYnqdwMwhyHt"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime+Unnormalized\n",
        "\n",
        "Download Dataset [CommViolPredUnnormalizedData.txt](https://archive.ics.uci.edu/ml/machine-learning-databases/00211/CommViolPredUnnormalizedData.txt)\n",
        "\n",
        "Download Header [CommViolPredUnnormalizedDataHeaders.csv](https://github.com/smnieee/ml_workshop/blob/master/session3/CommViolPredUnnormalizedDataHeaders.csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBx8-vpppIPa"
      },
      "source": [
        "### Upload Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYeidC4BoyYF"
      },
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9G0Eqrng7G3"
      },
      "source": [
        "### Alternative for using Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KUQY56oVyCm"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9d-BILjwLf8"
      },
      "source": [
        "## Load and View the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap5HmAD_p9MT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpmYscn3_cq7"
      },
      "source": [
        "The data file comes without a header column. We could enter this manually but there 147 columns. Let's just use a header file to bring in the column names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4GK801g6bnG"
      },
      "source": [
        "head = pd.read_csv('/content/CommViolPredUnnormalizedDataHeaders.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR0CtD7JDMF3"
      },
      "source": [
        "Now, we can use the column names of this empty DataFrame as the column names of our data file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI6vFHZowX92"
      },
      "source": [
        "df = pd.read_csv('/content/CommViolPredUnnormalizedData.txt', names=head.columns.values.tolist(),\n",
        "                 na_values='?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvoLcrg5Dchk"
      },
      "source": [
        "View the first 5 rows of data with `df.head()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0dyzSQWwqc4"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jAQ8lDzDuo4"
      },
      "source": [
        "## Extract the Data for Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB77ZuHmENBk"
      },
      "source": [
        "For our analysis we will look at the relationship between violent and non-violent crime.\n",
        "\n",
        "We want to exclude any data that has `NaN` for the columns of `nonViolPerPop` and `violentPerPop`. Then, we will look at the scatter plot to see what a trend might look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DZI1-AG6D0k"
      },
      "source": [
        "dfcln = df.dropna(subset=['popDensity','nonViolPerPop', 'violentPerPop'])\n",
        "dfcln.plot.scatter(x='nonViolPerPop',y='violentPerPop')\n",
        "dfcln.plot.scatter(x='popDensity',y='violentPerPop')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_df2oc5Kpsl"
      },
      "source": [
        "There appears to be an approximatley linear or quadratic relationship between the two measures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwWmTxtEQNdF"
      },
      "source": [
        "## Manually Fit Linear Model\n",
        "\n",
        "We will try to fit the data on our own to see how this works. Then we will use the `scikit-learn` tools for fitting the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-yCN01-Tvof"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUb2JrTiQmlo"
      },
      "source": [
        "# Assign the violent crimes data as the Y-data\n",
        "viol = dfcln['violentPerPop'].values\n",
        "N = len(viol)\n",
        "Y_data = viol.copy()\n",
        "\n",
        "nonviol = dfcln['nonViolPerPop'].values\n",
        "density = dfcln['popDensity'].values\n",
        "\n",
        "# Create a 2-D X-data for comparison\n",
        "X_data = np.ndarray((N,2))\n",
        "X_data[:,0] = nonviol.copy()\n",
        "X_data[:,1] = density.copy()\n",
        "\n",
        "print(f\"The number of samples is: {N}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blQGXhf_TfxV"
      },
      "source": [
        "### Set up number of samples in each set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "000HWv3kRvxk"
      },
      "source": [
        "test_pct = 0.1\n",
        "valid_pct = 0.2\n",
        "\n",
        "X_train_valid, X_test, Y_train_valid, Y_test = train_test_split(X_data, Y_data, test_size=test_pct)\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_valid, Y_train_valid, test_size=valid_pct)\n",
        "\n",
        "print(f\"Train Size: {len(Y_train)}\")\n",
        "print(f\"Validation Size: {len(Y_valid)}\")\n",
        "print(f\"Test Size: {len(Y_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3TXdBZNZdsU"
      },
      "source": [
        "### Create Function for Calculating Linear Output\n",
        "\n",
        "This function will take input data and parameters and return the error score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQjj0n62Ugmk"
      },
      "source": [
        "def my_simple_fit(X, y, intercept, slopes):\n",
        "  \"\"\"\n",
        "  Calculate mean squared error for manual linear fit.\n",
        "  \"\"\"\n",
        "  ycalc = intercept + slopes @ X.T\n",
        "  err = mean_squared_error(y, ycalc)\n",
        "  return err"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Hx9No9ecSn"
      },
      "source": [
        "# Define an intercept and slopes and caluclate the fit\n",
        "b = 0.0\n",
        "m = np.array([1.0, 1.0])\n",
        "\n",
        "err = my_simple_fit(X_train, Y_train, b, m)\n",
        "print(f\"Error is {err}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHWNOz2Fe6h0"
      },
      "source": [
        "# Once the parameters are optimal, compare to the validation set.\n",
        "val_err = my_simple_fit(X_valid, Y_valid, b, m)\n",
        "print(f\"The validation set error is {val_err}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j5vFx4jf32K"
      },
      "source": [
        "### Use Python Tools and Compare\n",
        "\n",
        "Let's let `scikit-learn` do the calculation and see how we did."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HYHaU8kfvVK"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb310DmRgkNO"
      },
      "source": [
        "# Create the linear regession object\n",
        "regr = LinearRegression()\n",
        "\n",
        "# Use the fit method to create the fit\n",
        "regr.fit(X_train, Y_train)\n",
        "\n",
        "# Print the coefficients\n",
        "print(f\"The intercept is {regr.intercept_} and the slopes are {regr.coef_}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP6bEWMxhZSu"
      },
      "source": [
        "Now, check the calculated model with the validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvJa5QtjhRVL"
      },
      "source": [
        "Y_pred = regr.predict(X_valid)\n",
        "mse_pred = mean_squared_error(Y_valid, Y_pred)\n",
        "print(f\"The MSE is {mse_pred}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvsxV8zDiBwP"
      },
      "source": [
        "Finally, check the results against the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVxI9oPth35v"
      },
      "source": [
        "Y_pred_test = regr.predict(X_test)\n",
        "mse_pred_test = mean_squared_error(Y_test, Y_pred_test)\n",
        "print(f\"The MSE is {mse_pred_test}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0E39ayCjBBk"
      },
      "source": [
        "## Polynomial Regression to the Data\n",
        "\n",
        "The linear approach was difficult to do manually. The data can be fit with a simple line but is that optimal? Now, we will try to use a polynomial to see how the model fits the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UXrlBq4jkfv"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sul5a8gokWLn"
      },
      "source": [
        "# Set up a quadratic polynomial\n",
        "quad = PolynomialFeatures(degree=2)\n",
        "\n",
        "# Create quadratic x-data\n",
        "Xq_train = quad.fit_transform(X_train)\n",
        "Xq_valid = quad.fit_transform(X_valid)\n",
        "Xq_test = quad.fit_transform(X_test)\n",
        "\n",
        "# Now use the new x-data in the linear regression\n",
        "qregr = LinearRegression(fit_intercept=False)\n",
        "\n",
        "qregr.fit(Xq_train, Y_train)\n",
        "\n",
        "Yq_pred = qregr.predict(Xq_train)\n",
        "mse_yq_train = mean_squared_error(Y_train, Yq_pred)\n",
        "\n",
        "# Print the MSE for the training data\n",
        "print(f\"The training data MSE is {mse_yq_train}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-axplOBmFNx"
      },
      "source": [
        "Yq_valid = qregr.predict(Xq_valid)\n",
        "Yq_test = qregr.predict(Xq_test)\n",
        "\n",
        "mse_yq_valid = mean_squared_error(Y_valid, Yq_valid)\n",
        "mse_yq_test = mean_squared_error(Y_test, Yq_test)\n",
        "\n",
        "# Print the validation and test results\n",
        "print(f\"The validation set MSE is {mse_yq_valid}\")\n",
        "print(f\"The test set MSE is {mse_yq_test}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fsChsfGidBq"
      },
      "source": [
        "## K-Fold Validation\n",
        "\n",
        "The previous example worked to just demonstrate how each step works and if the data showed a quadratic dependence on the data. Now, we want to run a cross-validation on the data set to find the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4pm0iLliSLL"
      },
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvyyOH0w5YRi"
      },
      "source": [
        "### Investigate KFold Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5qpdA4Tyq2B"
      },
      "source": [
        "Using the `KFold` object will automatically generate the indices for splitting our data up. If we iterate on the object it will give us each permutation of train and validation assignements. We can then see the error as we change the combinations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKtDh-lkyoyk"
      },
      "source": [
        "nfolds = 5\n",
        "kf = KFold(n_splits=nfolds)\n",
        "\n",
        "err_array = np.zeros(nfolds)\n",
        "\n",
        "n = 0\n",
        "for train_index, valid_index in kf.split(X_train_valid):\n",
        "  # Split up the data using KFold\n",
        "  Xkf_train, Xkf_valid = X_train_valid[train_index], X_train_valid[valid_index]\n",
        "  Ykf_train, Ykf_valid = Y_train_valid[train_index], Y_train_valid[valid_index]\n",
        "\n",
        "  # Use linear regression to fit and measure the data\n",
        "  regr.fit(Xkf_train, Ykf_train)\n",
        "  err_array[n] = mean_squared_error(Ykf_valid, regr.predict(Xkf_valid))\n",
        "  n += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfP24nEx1VcU"
      },
      "source": [
        "Now, lets look at the data accross the folds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiCsdM7c1Q79"
      },
      "source": [
        "perm_num = range(1, len(err_array)+1)\n",
        "\n",
        "plt.scatter(perm_num, err_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1jNc_JT1-lK"
      },
      "source": [
        "So, the error is obviously dependent on the selection of data in the training and in the validation sets. What if we save all the fit parameters and look at those?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwzMp9w713yQ"
      },
      "source": [
        "kf_intercepts = np.zeros(nfolds)\n",
        "kf_slopes = np.zeros((nfolds, 2))\n",
        "\n",
        "n = 0\n",
        "for train_index, valid_index in kf.split(X_train_valid):\n",
        "  # Split up the data using KFold\n",
        "  Xkf_train, Xkf_valid = X_train_valid[train_index], X_train_valid[valid_index]\n",
        "  Ykf_train, Ykf_valid = Y_train_valid[train_index], Y_train_valid[valid_index]\n",
        "\n",
        "  # Use linear regression to fit and measure the data\n",
        "  regr.fit(Xkf_train, Ykf_train)\n",
        "  kf_intercepts[n] = regr.intercept_\n",
        "  kf_slopes[n,:] = regr.coef_\n",
        "  err_array[n] = mean_squared_error(Ykf_valid, regr.predict(Xkf_valid))\n",
        "  n += 1\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.scatter(range(1,nfolds+1), kf_intercepts)\n",
        "plt.title('Intercepts')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba-Nt68L4cB0"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.scatter(range(1,nfolds+1), kf_slopes[:,0])\n",
        "plt.title('Slope for Nonviolent Crimes')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFK8Lhyt4cs4"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.scatter(range(1,nfolds+1), kf_slopes[:,1])\n",
        "plt.title('Slope for Population Density')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIm8GMDo5H2c"
      },
      "source": [
        "### Model Results after KFold\n",
        "\n",
        "Now, the average of the folding can be used and then tested against the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2898HHFp3eKY"
      },
      "source": [
        "mean_intercept = kf_intercepts.mean()\n",
        "mean_slopes = kf_slopes.mean(axis=0)\n",
        "\n",
        "new_regr = LinearRegression()\n",
        "new_regr.intercept_ = mean_intercept\n",
        "new_regr.coef_ = mean_slopes\n",
        "\n",
        "# Print the MSE for the test set\n",
        "final_mse = mean_squared_error(Y_test, new_regr.predict(X_test))\n",
        "print(f\"The MSE for the test set after KFolds of {nfolds} is {final_mse}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}