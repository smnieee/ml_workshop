{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to Unsupervised Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODuFs+IjhVAOsi/SSsk/Qs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smnieee/ml_workshop/blob/master/Intro_to_Unsupervised_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKPkE7BRtUor"
      },
      "source": [
        "# Introduction to Unsupervised Learning\n",
        "\n",
        "IEEE Southern Minnesota Section\n",
        "\n",
        "Machine Learning Workshop: Session 4\n",
        "\n",
        "April 19, 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKnqyXLOtr1B"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In previous workshops, we covered supervised learning methods, e.g. linear regression. The crux of these lessons was the assumption that there was an underlying structure or model to the data being analyzed. \n",
        "\n",
        "This notebook will work through unsupervised learning. We will begin with a simple clustering example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O-cmsR7Q6mL"
      },
      "source": [
        "# Overview of k-Means Cluestering\n",
        "\n",
        "\n",
        "Clustering is a set of methods for grouping data. Data are partitioned into groups based on similarities within the data. We do not know the similarities a priori but we begin with the data and look for them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0lVSbGdzsPa"
      },
      "source": [
        "## Download and Unzip the Data\n",
        "\n",
        "Data Website:\n",
        "http://cs.joensuu.fi/sipu/datasets/\n",
        "\n",
        "\n",
        "Data Citation:\n",
        "P. Fr√§nti R. Mariescu-Istodor and C. Zhong, \"XNN graph\" IAPR Joint Int. Workshop on Structural, Syntactic, and Statistical Pattern Recognition Merida, Mexico, LNCS 10029, 207-217, November 2016."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FquTAZbHz83T"
      },
      "source": [
        "!wget http://cs.joensuu.fi/sipu/datasets/g2-txt.zip\n",
        "!unzip \"g2-txt.zip\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvbL2IcU48l7"
      },
      "source": [
        "## Read in Data and Convert to Numpy Array\n",
        "\n",
        "The data in the csv is space separated. It needs to be read in and converted to a `numpy` array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlzm3msa0OHM"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "dlist = []\n",
        "\n",
        "with open(\"g2-2-40.txt\", 'r') as c:\n",
        "  creader = csv.reader(c, delimiter=\" \", skipinitialspace=True)\n",
        "\n",
        "  for row in creader:\n",
        "    dlist.append([float(r) for r in row])\n",
        "\n",
        "dlist = np.array(dlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZPpk3ow5QYf"
      },
      "source": [
        "### View the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NZMy93R1_Sz"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(dlist[:,0], dlist[:,1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a1UeWEy9oSh"
      },
      "source": [
        "## Implement the k-Means Algorithm\n",
        "\n",
        "The k-means algorithm is rather simple. To instill an understanding of the process we will implement it with basic code before trying to use more developed modules.\n",
        "\n",
        "The algorithm is really just a few steps:\n",
        "1. Pick the number of centroids, k.\n",
        "2. Randomly place k centroids.\n",
        "3. Repeat until converged:\n",
        "  1. Assign each point to the closest centroid.\n",
        "  2. Compute the new centroid from the mean of all points assigned to each group.\n",
        "4. Assess results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVXdBgy47Uvp"
      },
      "source": [
        "k = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lRRutuLAIGG"
      },
      "source": [
        "xmin, xmax = np.min(dlist[:,0]), np.max(dlist[:,0])\n",
        "ymin, ymax = np.min(dlist[:,1]), np.max(dlist[:,1])\n",
        "\n",
        "centroids = np.hstack((np.random.default_rng().uniform(xmin, xmax, (k,1)),\n",
        "                      np.random.default_rng().uniform(ymin,ymax, (k,1))))\n",
        "\n",
        "\n",
        "plt.subplots(figsize=(16,9))\n",
        "plt.scatter(dlist[:,0], dlist[:,1])\n",
        "plt.scatter(centroids[:,0], centroids[:,1], marker='o', c='red', s=200)\n",
        "\n",
        "display(centroids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3gbNrIsC66q"
      },
      "source": [
        "centers_list = [centroids[i].copy() for i in range(k)]\n",
        "\n",
        "for n in range(10):\n",
        "  cnt = np.zeros(k)\n",
        "  cent_sum = np.zeros_like(centroids)\n",
        "  for d in dlist:\n",
        "    diffs = [np.sum(np.square(d - c)) for c in centroids]\n",
        "    i = np.argmin(diffs)\n",
        "    cnt[i] += 1\n",
        "    cent_sum[i] += d\n",
        "\n",
        "  for m in range(k):\n",
        "    centroids[m] = cent_sum[m] / cnt[m]\n",
        "    centers_list[m] = np.vstack((centers_list[m], centroids[m]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ylqtj_LB3BD"
      },
      "source": [
        "plt.subplots(figsize=(16,12))\n",
        "plt.scatter(dlist[:,0], dlist[:,1])\n",
        "for center in centers_list:\n",
        "  plt.scatter(center[:,0], center[:,1], marker='o', edgecolors='black', s=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UhJBLrbPLNO"
      },
      "source": [
        "### Plot the Convergence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEduII0WFfEi"
      },
      "source": [
        "fig, ax = plt.subplots(2,2, figsize=(16,9))\n",
        "\n",
        "ax[0,0].plot(centers_list[0][:,0])\n",
        "ax[0,0].set_title('X-Values for Center 1')\n",
        "ax[1,0].plot(centers_list[0][:,1])\n",
        "ax[1,0].set_title('Y-Values for Center 1')\n",
        "\n",
        "ax[0,1].plot(centers_list[1][:,0])\n",
        "ax[0,1].set_title('X-Values for Center 2')\n",
        "ax[1,1].plot(centers_list[1][:,1])\n",
        "ax[1,1].set_title('Y-Values for Center 2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iShUtYHvT-UH"
      },
      "source": [
        "### Plot the Final Labels\n",
        "\n",
        "Now show how the final groupings based on final centroids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwHhwrEZULoX"
      },
      "source": [
        "final_labels = np.zeros(len(dlist))\n",
        "\n",
        "for n,d in enumerate(dlist):\n",
        "  diffs = [np.sum(np.square(d - c)) for c in centroids]\n",
        "  i = np.argmin(diffs)\n",
        "  final_labels[n] = i\n",
        "\n",
        "plt.subplots(figsize=(16,9))\n",
        "plt.scatter(dlist[:,0], dlist[:,1], c=final_labels, edgecolors='black')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTYx0oKLUMJ4"
      },
      "source": [
        "### Cross check with 2D histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AThK3_pOQg5S"
      },
      "source": [
        "plt.subplots(figsize=(16,9))\n",
        "plt.hist2d(dlist[:,0], dlist[:,1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnOGce3wQYCT"
      },
      "source": [
        "# K-Means with Scikit-Learn\n",
        "\n",
        "Of course, we don't have to implement this manually. There are packages that support clustering. Specfically, we will again use scikit-learn to investigate the data.\n",
        "\n",
        "\n",
        "Reference:\n",
        "https://realpython.com/k-means-clustering-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmyBFkJJ9zWw"
      },
      "source": [
        "## Preprocessing Data\n",
        "\n",
        "Most data processing packages expect the data to be of certain ranges and values. Therefore, our data needs to be preprocessed to 'look like' the expect inputs of the tools.\n",
        "\n",
        "Specifically, our data needs to be scaled so that it has a mean of 0 and a standard deviation of 1 for each dimension. The scikit-learn package has a scaler function that will do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emj8kWdK-g1T"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(dlist)\n",
        "\n",
        "plt.subplots(figsize=(16,12))\n",
        "plt.scatter(scaled_data[:,0], scaled_data[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M28TURGTB5HR"
      },
      "source": [
        "## Create a k-means Class from scikit-learn\n",
        "\n",
        "The k-means estimator can be created by passing some setup parameters to the Kmeans class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiKQvEGZ--52"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(\n",
        "    init = \"random\",\n",
        "    n_init = 10,\n",
        "    max_iter = 10,\n",
        "    n_clusters = k\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7577lhPtC4Nb"
      },
      "source": [
        "## Run k-means Fit using Estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4zYpphkCyTw"
      },
      "source": [
        "kmeans.fit(scaled_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEAwr8diDHVk"
      },
      "source": [
        "# The number of iterations needed for convergence\n",
        "kmeans.n_iter_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40pkRkgmDWat"
      },
      "source": [
        "# The centroids found\n",
        "scaler.inverse_transform(kmeans.cluster_centers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKdMpbr8DoBm"
      },
      "source": [
        "# The best SSE (sum squared error)\n",
        "kmeans.inertia_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk2BI_eRDvLI"
      },
      "source": [
        "plt.subplots(figsize=(16,12))\n",
        "plt.scatter(scaled_data[:,0], scaled_data[:,1], c=kmeans.labels_, edgecolors='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_bbMlI-EYQl"
      },
      "source": [
        "## Find the Best Number of Clusters\n",
        "\n",
        "For our data, the number of clusters to use was just decided by looking at the data on a plot. Most of the time, it won't be that simple. There are better methods for finding an optimal number of clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzSLZx-KEJHK"
      },
      "source": [
        "# Find the SSE for various number of clusters\n",
        "\n",
        "errs = []\n",
        "centers_list = []\n",
        "\n",
        "for ktest in range(1,10):\n",
        "  kmeans = KMeans(\n",
        "    init = \"random\",\n",
        "    n_init = 10,\n",
        "    max_iter = 10,\n",
        "    n_clusters = ktest\n",
        "  )\n",
        "\n",
        "  kmeans.fit(scaled_data)\n",
        "  errs.append(kmeans.inertia_)\n",
        "  centers_list.append(scaler.inverse_transform(kmeans.cluster_centers_))\n",
        "\n",
        "  print(f\"Number of Clusters: {ktest}\")\n",
        "  print(f\"SSE: {kmeans.inertia_}\")\n",
        "  print(f\"Centers: {centers_list[-1]}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwls0eutHfti"
      },
      "source": [
        "# Plot the Error versus Number of Clusters\n",
        "plt.subplots(figsize=(16,12))\n",
        "plt.plot(range(1,10), errs)\n",
        "plt.title(\"SSE versus Number of Clusters\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zDXjdkAIXi9"
      },
      "source": [
        "### Silhouette Coefficients\n",
        "\n",
        "The silhouette coefficient is an alternate measurement of our clustering. Instead of SSE, it looks at how well data fits in a given cluster _and_ how it does not fit in others.\n",
        "\n",
        "An alternate method for choosing the number of clusters is to look at the silhouette coefficients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLwOGesvH_SB"
      },
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Find the silhouette coefficient for various number of clusters\n",
        "\n",
        "coeffs = []\n",
        "centers_list = []\n",
        "\n",
        "for ktest in range(2,10):\n",
        "  kmeans = KMeans(\n",
        "    init = \"random\",\n",
        "    n_init = 10,\n",
        "    max_iter = 10,\n",
        "    n_clusters = ktest\n",
        "  )\n",
        "\n",
        "  kmeans.fit(scaled_data)\n",
        "  score = silhouette_score(scaled_data, kmeans.labels_)\n",
        "  coeffs.append(score)\n",
        "  centers_list.append(scaler.inverse_transform(kmeans.cluster_centers_))\n",
        "\n",
        "  print(f\"Number of Clusters: {ktest}\")\n",
        "  print(f\"Silhouette Score: {coeffs[-1]}\")\n",
        "  print(f\"Centers: {centers_list[-1]}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-NFwayGJnZz"
      },
      "source": [
        "# Plot the Score versus Number of Clusters\n",
        "plt.subplots(figsize=(16,12))\n",
        "plt.plot(range(2,10), coeffs)\n",
        "plt.title(\"Silhouette Scores\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ48rP8hKFSD"
      },
      "source": [
        "kmeans = KMeans(\n",
        "  init = \"random\",\n",
        "  n_init = 10,\n",
        "  max_iter = 10,\n",
        "  n_clusters = 4\n",
        ")\n",
        "\n",
        "kmeans.fit(scaled_data)\n",
        "\n",
        "plt.subplots(figsize=(16,12))\n",
        "plt.scatter(scaled_data[:,0], scaled_data[:,1], c=kmeans.labels_, \n",
        "            edgecolors='gray'\n",
        ")\n",
        "\n",
        "plt.title(\"Labeled Data with K=4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNpWdRmYKqvu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}